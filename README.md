# FinalProject

## Set up

1) Clone repository
2) Run set_up.sh script in the root

Woala now you have set up all infrastructure with all dags.

## Infrastructure

Infrastructure was built using Docker compose and has such services:

1) Airflow with Celery
2) Postgres for storing results of aggregations;
3) Adminer provides web based interface to interact with postgres
4) Redis to store results of preprocessing
5) Kafka

## Generation

### “Static” generator

#### Description

Script that generates “static” data based on possible locations, possible devices types and user provided arguments.

#### Depends on

Separate files with a list of locations(countries) available and a list of devices' types available. Input parameters

#### Located

In generation/src/generators

### “Dynamic” generator

#### Description

Script that generates “dynamic” data based on “static” data and user provided arguments.

#### Depends on

“Static” data.

#### Located

In generation/src/generators

### Hot map generator

#### Description

Script that generates hot map data based on “dynamic” data particularly based on views and user provided arguments.

#### Depends on

Views data.

#### Located

In PythonSpark/Streaming

## Aggregations

### Conversion rate aggregation

#### Description

Counts conversion rate (purchases count / views count) for each item. In development mode writes to Postgres and in
production writes to BigQuerry

#### Depends on

Views, purchases and ips data.

#### Located

In ScalaSpark/src/scala/Aggregations/Purchases

In PythonSpark/Aggregations/Purchases

### Grouped items aggregation

#### Description

Counts an amount of times some items were bought together. In development mode writes to Postgres and in production
writes to BigQuerry

#### Depends on

Purchases and ips data.

#### Located

In ScalaSpark/src/scala/Aggregations/Purchase

In PythonSpark/Aggregations/Purchases

### Location sell share count aggregation

#### Description

Counts share of number of purchases in locations(countries). In development mode writes to Postgres and in production
writes to BigQuery

#### Depends on

Purchases and ips data.

#### Located

In ScalaSpark/src/scala/Aggregations/Purchases

In PythonSpark/Aggregations/Purchases

### Profit by item aggregation

#### Description

Counts profit generated by an item. In development mode writes to Postgres and in production writes to BigQuerry

#### Depends on

Purchases, ips, items data.

#### Located

In ScalaSpark/src/scala/Aggregations/Purchases

In PythonSpark/Aggregations/Purchases

### Item's views count aggregation

#### Description

Counts total number of views generated by an item. In development mode writes to Postgres and in production writes to
BigQuery

#### Depends on

Views and ips data.

#### Located

In ScalaSpark/src/scala/Aggregations/Views

In PythonSpark/Aggregations/Views

### Item's views share aggregation

#### Description

Counts share of views generated by an item. In development mode writes to Postgres and in production writes to BigQuerry

#### Depends on

Views and ips data.

#### Located

In ScalaSpark/src/scala/Aggregations/Views

In PythonSpark/Aggregations/Views

### Hot map streaming aggregation

#### Description

Counts a number of times, square was pointed by the user on some page. In development mode writes to Postgres and in
production writes to BigQuery.

#### Depends on

Kafka topic with hot map data.

#### Located

In PythonSpark/Streaming

## Dags

### Generation

#### “Static” data generation

##### Description

This dag runs “static” data generation. Parameters for preprocessing are provided using the static_generator_config.json
file.

##### Structure

Consist from only one task called run_job that runs generation itself.

#### Located

In generation/src/dags

#### “Dynamic” data generation

##### Description

This dag runs “static” data generation. Parameters for preprocessing are provided using the static_generator_config.json
file.

##### Structure

Consist from only one task called run_job that runs generation itself.

#### Located

In generation/src/dags

### Preprocessing

#### Views preprocessing

##### Description

This dag runs view preprocessing. Parameters for preprocessing are provided using the views_preprocessing_config.json
file.

##### Structure

Consist from only one task called run_job that runs preprocessing itself.

#### Located

Dev: DagsFactory/dags/Preprocessing/dev/dags

Prod: DagsFactory/dags/Preprocessing/prod/dags

#### Purchases preprocessing

##### Description

This dag runs view preprocessing. Parameters for preprocessing are provided using the
purchases_preprocessing_config.json file.

##### Structure

Consist from only one task called run_job that runs preprocessing itself.

#### Located

Dev: DagsFactory/dags/Preprocessing/dev/dags

Prod: DagsFactory/dags/Preprocessing/prod/dags

### Aggregations

#### Conversion rate aggregation

##### Description

This dag runs conversion rate aggregation. Parameters for aggregation are provided using the
conversion_rate_aggregation_config.json file.

##### Structure

Consist from only one task called run_job that runs aggregation itself

#### Located

Dev: DagsFactory/dags/Aggregations/dev/dags

Prod: DagsFactory/dags/Aggregations/prod/dags

#### Grouped items aggregation

##### Description

This dag runs conversion rate aggregation. Parameters for aggregation are provided using the
grouped_items_aggregation_config.json file.

##### Structure

Consist from only one task called run_job that runs aggregation itself.

#### Located

Dev: DagsFactory/dags/Aggregations/dev/dags

Prod: DagsFactory/dags/Aggregations/prod/dags

#### Location sell share count aggregation

##### Description

This dag runs conversion rate aggregation. Parameters for aggregation are provided using the
location_sell_number_share_aggregation_config.json file.

##### Structure

Consist from only one task called run_job that runs aggregation itself.

#### Located

Dev: DagsFactory/dags/Aggregations/dev/dags

Prod: DagsFactory/dags/Aggregations/prod/dags

#### Profit by item aggregation

##### Description

This dag runs conversion rate aggregation. Parameters for aggregation are provided using the
profit_by_item_aggregation_config.json file.

##### Structure

Consist from only one task called run_job that runs aggregation itself.

#### Located

Dev: DagsFactory/dags/Aggregations/dev/dags

Prod: DagsFactory/dags/Aggregations/prod/dags

#### Item's views count aggregation

##### Description

This dag runs conversion rate aggregation. Parameters for aggregation are provided using the
items_views_count_aggregation_config.json file.

##### Structure

Consist from only one task called run_job that runs aggregation itself.

#### Located

Dev: DagsFactory/dags/Aggregations/dev/dags

Prod: DagsFactory/dags/Aggregations/prod/dags

#### Item's views share aggregation

##### Description

This dag runs conversion rate aggregation. Parameters for aggregation are provided using the
items_views_share_aggregation_config.json file.

##### Structure

Consist from only one task called run_job that runs aggregation itself.

#### Located

Dev: DagsFactory/dags/Aggregations/dev/dags

Prod: DagsFactory/dags/Aggregations/prod/dags

## Data

### "Static" data:

1) users.csv file contains data about users and devices they used to log in <br> columns:
    1) user_id - is of a user;
    2) device_name - type of the device used by user;
    3) ip - of a device.
2) ips.csv file contains data about ips <br> columns:
    1) ip - ip of a device used by user;
    2) country - country, which this ip belongs to.
3) items.csv file contains data about items <br> columns:
    1) item_id - id of an item
    2) price - price of an item

### "Dynamic" data:

1) views.csv file contains data about item views:
    1) user_id - id of a user, who made the view;
    2) device - type of the device user used;
    3) ip - ip of the device;
    4) item_id - id of an item user viewed;
    5) ts - time, when user made a view.
2) purchases.json file contains data about purchases:
    1) user_id - id of a user, who made the purchase;
    2) ip - of a device used for making the purchase;
    3) ts - time, when the purchase was made;
    4) order_id - id of the purchase;
    5) items - list of (item_id, amount) pairs:
        1) item_id - id of an item purchased;
        2) amount - amount of an item purchased.

### Streaming data: <br>

Data is pushed directly to the kafka topic. Data has such structure:

1) key - (square_id, item_id) pair:
    1) square_id - corresponds to an id of square on page;
    2) item_id - corresponds to a page of an item with id item_id;
2) value - (user_id, time) pair:
    1) user_id - id of a user;
    2) time - time when user viewed the square;
    